"use strict";(globalThis.webpackChunkrobotic_book=globalThis.webpackChunkrobotic_book||[]).push([[336],{4639:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"module3-ai-brain/isaac-ros-gems-perception","title":"Isaac ROS GEMs for AprilTag and PeopleNet","description":"This chapter continues our exploration of NVIDIA Isaac ROS GEMs, focusing on their application in specific perception tasks: AprilTag detection for robust localization and object tracking, and PeopleNet/Pose estimation for human detection and understanding. These GPU-accelerated modules are crucial for enabling robots to interact intelligently and safely with their environment.","source":"@site/docs/module3-ai-brain/04-isaac-ros-gems-perception.mdx","sourceDirName":"module3-ai-brain","slug":"/module3-ai-brain/isaac-ros-gems-perception","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/isaac-ros-gems-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/yourusername/physical-ai-humanoid-book/tree/main/docs/module3-ai-brain/04-isaac-ros-gems-perception.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS GEMs for Visual SLAM","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/isaac-ros-gems-slam"},"next":{"title":"Nav2 Configuration for Unstable Bipedal Platforms","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/nav2-bipedal"}}');var t=i(4848),o=i(8453);const r={},s="Isaac ROS GEMs for AprilTag and PeopleNet",c={},l=[{value:"AprilTag Detection",id:"apriltag-detection",level:2},{value:"PeopleNet / Pose Estimation",id:"peoplenet--pose-estimation",level:2},{value:"Implementing Perception with Isaac ROS",id:"implementing-perception-with-isaac-ros",level:2},{value:"Example: Human and Object Detection in a Simulated Environment (Conceptual Isaac ROS Perception)",id:"example-human-and-object-detection-in-a-simulated-environment-conceptual-isaac-ros-perception",level:2},{value:"1. Conceptual ROS 2 Launch File (<code>perception_example.launch.py</code>)",id:"1-conceptual-ros-2-launch-file-perception_examplelaunchpy",level:3},{value:"Explanation",id:"explanation",level:3},{value:"How to Use (Conceptual)",id:"how-to-use-conceptual",level:3},{value:"Reference",id:"reference",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"isaac-ros-gems-for-apriltag-and-peoplenet",children:"Isaac ROS GEMs for AprilTag and PeopleNet"})}),"\n",(0,t.jsx)(n.p,{children:"This chapter continues our exploration of NVIDIA Isaac ROS GEMs, focusing on their application in specific perception tasks: AprilTag detection for robust localization and object tracking, and PeopleNet/Pose estimation for human detection and understanding. These GPU-accelerated modules are crucial for enabling robots to interact intelligently and safely with their environment."}),"\n",(0,t.jsx)(n.h2,{id:"apriltag-detection",children:"AprilTag Detection"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Purpose"}),": Detecting fiducial markers (AprilTags) for precise relative localization, object identification, and camera calibration."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isaac ROS AprilTag GEM"}),": High-performance AprilTag detection on NVIDIA GPUs."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Benefits"}),": Robustness in varying lighting conditions, fast detection rates, accurate pose estimation."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"peoplenet--pose-estimation",children:"PeopleNet / Pose Estimation"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Purpose"}),": Detecting humans in a scene and estimating their pose (keypoints) for human-robot collaboration, safety, and social navigation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isaac ROS PeopleNet GEM"}),": A highly optimized neural network for human detection."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Benefits"}),": Real-time performance on edge devices, ability to track multiple individuals, understanding human intent through pose."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"implementing-perception-with-isaac-ros",children:"Implementing Perception with Isaac ROS"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Installation and Setup"}),": Integrating AprilTag and PeopleNet GEMs into a ROS 2 workspace."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configuration"}),": Tuning parameters for different camera types and application scenarios."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Integration with ROS 2"}),": Publishing detection results (bounding boxes, poses, tag IDs) to ROS 2 topics."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"example-human-and-object-detection-in-a-simulated-environment-conceptual-isaac-ros-perception",children:"Example: Human and Object Detection in a Simulated Environment (Conceptual Isaac ROS Perception)"}),"\n",(0,t.jsx)(n.p,{children:"This conceptual example demonstrates how to integrate Isaac ROS AprilTag and PeopleNet GEMs within a ROS 2 launch file to detect fiducial markers (AprilTags) and humans in a simulated environment."}),"\n",(0,t.jsxs)(n.h3,{id:"1-conceptual-ros-2-launch-file-perception_examplelaunchpy",children:["1. Conceptual ROS 2 Launch File (",(0,t.jsx)(n.code,{children:"perception_example.launch.py"}),")"]}),"\n",(0,t.jsx)(n.p,{children:"This Python launch file would typically:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Launch your simulated camera (e.g., from Isaac Sim via ",(0,t.jsx)(n.code,{children:"ros_bridge"}),")."]}),"\n",(0,t.jsx)(n.li,{children:"Launch the Isaac ROS AprilTag node."}),"\n",(0,t.jsx)(n.li,{children:"Launch the Isaac ROS PeopleNet node."}),"\n",(0,t.jsx)(n.li,{children:"(Optionally) Launch RViz2 to visualize the detections."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Conceptual ROS 2 Launch File: perception_example.launch.py\r\nimport os\r\nfrom ament_index_python.packages import get_package_share_directory\r\nfrom launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\n\r\ndef generate_launch_description():\r\n    # Path to Isaac ROS AprilTag package\r\n    # apriltag_dir = get_package_share_directory('isaac_ros_apriltag')\r\n    # Path to Isaac ROS PeopleNet package\r\n    # peoplenet_dir = get_package_share_directory('isaac_ros_dnn_image_encoder') # PeopleNet is part of this\r\n\r\n    # --- Isaac ROS AprilTag Node ---\r\n    apriltag_node = Node(\r\n        package='isaac_ros_apriltag',\r\n        executable='isaac_ros_apriltag',\r\n        name='apriltag_node',\r\n        output='screen',\r\n        parameters=[\r\n            {\r\n                'image_qos_profile': 'SENSOR_DATA',\r\n                'camera_info_qos_profile': 'SENSOR_DATA',\r\n                'output_qos_profile': 'SENSOR_DATA',\r\n                'size': 0.152, # Size of the AprilTag in meters\r\n                'max_tags': 10,\r\n                'tag_family': 'TAG36H11',\r\n                # Input topic from the simulated camera\r\n                'image_topic': '/camera/image_raw',\r\n                'camera_info_topic': '/camera/camera_info',\r\n            }\r\n        ],\r\n        remappings=[\r\n            ('tag_detections', '/apriltag_detections'),\r\n            ('tag_poses', '/apriltag_poses'),\r\n        ]\r\n    )\r\n\r\n    # --- Isaac ROS PeopleNet Node (requires image_proc and other setup) ---\r\n    # This is a simplified representation. PeopleNet typically involves multiple\r\n    # nodes for image encoding, inference, and decoding.\r\n    peoplenet_inference_node = Node(\r\n        package='isaac_ros_detectnet', # Package name for DetectNetv2 (used by PeopleNet)\r\n        executable='isaac_ros_detectnet',\r\n        name='peoplenet_inference',\r\n        output='screen',\r\n        parameters=[\r\n            {\r\n                'model_path': '/path/to/peoplenet.etlt', # Path to the PeopleNet model\r\n                'label_path': '/path/to/peoplenet_labels.txt',\r\n                'image_mean': [0.5, 0.5, 0.5],\r\n                'image_std': [0.5, 0.5, 0.5],\r\n                'input_binding_names': ['input_tensor'],\r\n                'output_binding_names': ['output_bbox/argmax', 'output_cov/Sigmoid'],\r\n                'input_tensor_shape': [1, 3, 544, 960], # Example shape\r\n                # Input topic from the simulated camera\r\n                'image_topic': '/camera/image_raw',\r\n            }\r\n        ],\r\n        remappings=[\r\n            ('detections_output', '/peoplenet_detections'),\r\n        ]\r\n    )\r\n\r\n    # Conceptual RViz2 node for visualization (uncomment if needed)\r\n    # rviz_node = Node(\r\n    #     package='rviz2',\r\n    #     executable='rviz2',\r\n    #     name='rviz_perception',\r\n    #     output='screen',\r\n    # )\r\n\r\n    return LaunchDescription([\r\n        apriltag_node,\r\n        peoplenet_inference_node,\r\n        # rviz_node # Uncomment for visualization\r\n    ])\n"})}),"\n",(0,t.jsx)(n.h3,{id:"explanation",children:"Explanation"}),"\n",(0,t.jsx)(n.p,{children:"This conceptual launch file demonstrates how to setup perception GEMs:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AprilTag Node"}),": Configures ",(0,t.jsx)(n.code,{children:"isaac_ros_apriltag"})," to detect tags from the simulated camera's image stream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PeopleNet Node"}),": A simplified representation of ",(0,t.jsx)(n.code,{children:"isaac_ros_detectnet"})," configured to run a PeopleNet model for human detection. Note that PeopleNet often involves an encoder, inference, and decoder."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input Topics"}),": Both nodes subscribe to the simulated camera's ",(0,t.jsx)(n.code,{children:"image_raw"})," and ",(0,t.jsx)(n.code,{children:"camera_info"})," topics."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output Topics"}),": They publish their detection results to dedicated topics (e.g., ",(0,t.jsx)(n.code,{children:"/apriltag_detections"}),", ",(0,t.jsx)(n.code,{children:"/peoplenet_detections"}),")."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"how-to-use-conceptual",children:"How to Use (Conceptual)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Set up your simulated environment (e.g., in Isaac Sim) with a camera publishing ROS 2 topics and containing AprilTags and simulated humans."}),"\n",(0,t.jsxs)(n.li,{children:["Ensure you have the necessary Isaac ROS packages (",(0,t.jsx)(n.code,{children:"isaac_ros_apriltag"}),", ",(0,t.jsx)(n.code,{children:"isaac_ros_detectnet"}),", etc.) and the PeopleNet model installed in your ROS 2 workspace."]}),"\n",(0,t.jsx)(n.li,{children:"Build your workspace and source it."}),"\n",(0,t.jsxs)(n.li,{children:["Launch the perception example:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ros2 launch your_package_name perception_example.launch.py\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Use ",(0,t.jsx)(n.code,{children:"ros2 topic echo /apriltag_detections"})," or ",(0,t.jsx)(n.code,{children:"ros2 topic echo /peoplenet_detections"})," to view the outputs, or RViz2 to visualize the detections overlaid on the camera feed."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"reference",children:"Reference"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"examples/ros2_isaac_gems/isaac_ros_perception_example/"})," (Contains a placeholder ROS 2 package for this)"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var a=i(6540);const t={},o=a.createContext(t);function r(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);
"use strict";(globalThis.webpackChunkrobotic_book=globalThis.webpackChunkrobotic_book||[]).push([[653],{1795:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module2-digital-twin/unity-visualization","title":"Unity for Visualization and HRI Studies","description":"This chapter explores the use of Unity, a powerful real-time 3D development platform, for advanced visualization and Human-Robot Interaction (HRI) studies within the context of digital twins. Unity offers robust rendering capabilities, physics, and an extensive asset store, making it an excellent choice for creating compelling robotic simulations and user interfaces.","source":"@site/docs/module2-digital-twin/06-unity-visualization.mdx","sourceDirName":"module2-digital-twin","slug":"/module2-digital-twin/unity-visualization","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module2-digital-twin/unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/yourusername/physical-ai-humanoid-book/tree/main/docs/module2-digital-twin/06-unity-visualization.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"High-Fidelity Environments (Isaac Sim + Omniverse)","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module2-digital-twin/high-fidelity-environments"},"next":{"title":"Module 3 \u2013 The AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/"}}');var o=i(4848),r=i(8453);const s={},a="Unity for Visualization and HRI Studies",l={},c=[{value:"Why Unity for Robotics Visualization?",id:"why-unity-for-robotics-visualization",level:2},{value:"Integrating Unity with Digital Twins",id:"integrating-unity-with-digital-twins",level:2},{value:"Human-Robot Interaction (HRI) Studies",id:"human-robot-interaction-hri-studies",level:2},{value:"Example: Unity Dashboard for Humanoid Control (Conceptual Setup)",id:"example-unity-dashboard-for-humanoid-control-conceptual-setup",level:2},{value:"1. Conceptual Unity Project Structure",id:"1-conceptual-unity-project-structure",level:3},{value:"2. ROS-Unity Integration (Conceptual)",id:"2-ros-unity-integration-conceptual",level:3},{value:"3. HRI Dashboard Layout (<code>unity_hri_layout.json</code>)",id:"3-hri-dashboard-layout-unity_hri_layoutjson",level:3},{value:"4. Conceptual Script Snippet (<code>CommandInput.cs</code>)",id:"4-conceptual-script-snippet-commandinputcs",level:3},{value:"Reference",id:"reference",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"unity-for-visualization-and-hri-studies",children:"Unity for Visualization and HRI Studies"})}),"\n",(0,o.jsx)(e.p,{children:"This chapter explores the use of Unity, a powerful real-time 3D development platform, for advanced visualization and Human-Robot Interaction (HRI) studies within the context of digital twins. Unity offers robust rendering capabilities, physics, and an extensive asset store, making it an excellent choice for creating compelling robotic simulations and user interfaces."}),"\n",(0,o.jsx)(e.h2,{id:"why-unity-for-robotics-visualization",children:"Why Unity for Robotics Visualization?"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-Quality Rendering"}),": Create photorealistic robot and environment visualizations."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Interactive Experiences"}),": Develop custom user interfaces and interactive HRI scenarios."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cross-Platform Deployment"}),": Deploy visualizations to various platforms (desktop, web, VR/AR)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Asset Store"}),": Access a vast library of 3D models, textures, and tools."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"integrating-unity-with-digital-twins",children:"Integrating Unity with Digital Twins"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS Unity Integration"}),": Using the ",(0,o.jsx)(e.code,{children:"ROS-TCP-Connector"})," or other packages to stream data between ROS 2 and Unity."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time Data Visualization"}),": Displaying sensor data, robot states, and planned trajectories."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Physics Engine Comparison"}),": Understanding the differences between Unity's built-in physics and external simulators like Gazebo or Isaac Sim."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"human-robot-interaction-hri-studies",children:"Human-Robot Interaction (HRI) Studies"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Scenario Design"}),": Creating controlled environments for studying human interaction with robots."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"User Interface Development"}),": Building intuitive dashboards and control panels in Unity."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Data Collection"}),": Recording human responses and robot behaviors during HRI experiments."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"example-unity-dashboard-for-humanoid-control-conceptual-setup",children:"Example: Unity Dashboard for Humanoid Control (Conceptual Setup)"}),"\n",(0,o.jsxs)(e.p,{children:["This conceptual example outlines how you might set up a Unity project to create a Human-Robot Interaction (HRI) dashboard for controlling and visualizing a simulated humanoid robot, integrating with ROS 2. We'll reference ",(0,o.jsx)(e.code,{children:"examples/environments/unity_hri_layout.json"})," for the dashboard layout."]}),"\n",(0,o.jsx)(e.h3,{id:"1-conceptual-unity-project-structure",children:"1. Conceptual Unity Project Structure"}),"\n",(0,o.jsx)(e.p,{children:"A typical Unity project for robotics HRI might look like this:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"UnityProject/\r\n\u251c\u2500\u2500 Assets/\r\n\u2502   \u251c\u2500\u2500 Scenes/\r\n\u2502   \u2502   \u2514\u2500\u2500 MainHRI.unity          # Main scene for the dashboard\r\n\u2502   \u251c\u2500\u2500 Scripts/\r\n\u2502   \u2502   \u251c\u2500\u2500 RosConnector.cs        # Handles ROS 2 communication (e.g., via ROS-TCP-Connector)\r\n\u2502   \u2502   \u251c\u2500\u2500 RobotVisualizer.cs     # Displays robot model and state\r\n\u2502   \u2502   \u251c\u2500\u2500 SensorDisplay.cs       # Renders sensor data (LiDAR, Depth, IMU)\r\n\u2502   \u2502   \u2514\u2500\u2500 CommandInput.cs        # Manages sending commands to the robot\r\n\u2502   \u251c\u2500\u2500 Prefabs/\r\n\u2502   \u2502   \u2514\u2500\u2500 HumanoidRobot.prefab   # 3D model of your humanoid robot\r\n\u2502   \u251c\u2500\u2500 UI/\r\n\u2502   \u2502   \u2514\u2500\u2500 DashboardCanvas.prefab # UI elements for the dashboard\r\n\u2502   \u2514\u2500\u2500 Resources/                 # Any assets loaded at runtime\r\n\u2502       \u2514\u2500\u2500 unity_hri_layout.json  # Our conceptual layout definition\r\n\u251c\u2500\u2500 ProjectSettings/\r\n\u2514\u2500\u2500 Packages/\r\n    \u2514\u2500\u2500 com.unity.robotics.ros-tcp-connector/ # ROS-TCP-Connector package\n"})}),"\n",(0,o.jsx)(e.h3,{id:"2-ros-unity-integration-conceptual",children:"2. ROS-Unity Integration (Conceptual)"}),"\n",(0,o.jsxs)(e.p,{children:["The ",(0,o.jsx)(e.code,{children:"RosConnector.cs"})," script would be responsible for establishing communication with your ROS 2 network, typically using a package like ",(0,o.jsx)(e.code,{children:"ROS-TCP-Connector"}),". It would:"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Subscribe"})," to ROS 2 topics publishing robot state, sensor data (from your digital twin in Isaac Sim/Gazebo)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Publish"})," to ROS 2 topics or action goals for robot commands."]}),"\n"]}),"\n",(0,o.jsxs)(e.h3,{id:"3-hri-dashboard-layout-unity_hri_layoutjson",children:["3. HRI Dashboard Layout (",(0,o.jsx)(e.code,{children:"unity_hri_layout.json"}),")"]}),"\n",(0,o.jsxs)(e.p,{children:["Our conceptual dashboard layout, as defined in ",(0,o.jsx)(e.code,{children:"examples/environments/unity_hri_layout.json"}),", describes the different panels and their functions:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-json",children:'{\r\n  "layout_name": "Humanoid Control Dashboard",\r\n  "panels": [\r\n    {\r\n      "type": "RobotView",\r\n      "position": [0, 0],\r\n      "size": [800, 600]\r\n    },\r\n    {\r\n      "type": "SensorDataDisplay",\r\n      "position": [800, 0],\r\n      "size": [400, 300],\r\n      "data_sources": ["LiDAR", "IMU"]\r\n    },\r\n    {\r\n      "type": "CommandInput",\r\n      "position": [800, 300],\r\n      "size": [400, 300],\r\n      "command_types": ["joint_control", "high_level_goals"]\r\n    }\r\n  ]\r\n}\n'})}),"\n",(0,o.jsxs)(e.p,{children:["This JSON would be read by a Unity script (e.g., ",(0,o.jsx)(e.code,{children:"DashboardBuilder.cs"})," not shown) to dynamically arrange UI elements for the robot view, sensor data displays, and command input controls."]}),"\n",(0,o.jsxs)(e.h3,{id:"4-conceptual-script-snippet-commandinputcs",children:["4. Conceptual Script Snippet (",(0,o.jsx)(e.code,{children:"CommandInput.cs"}),")"]}),"\n",(0,o.jsxs)(e.p,{children:["Here's a conceptual C# script snippet for a ",(0,o.jsx)(e.code,{children:"CommandInput"})," component that might send a high-level goal based on user input:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Conceptual C# script in Unity (CommandInput.cs)\r\nusing UnityEngine;\r\nusing UnityEngine.UI;\r\n// using RosMessageTypes.Std; // Assuming ROS-TCP-Connector\r\n// using Unity.Robotics.ROSTCPConnector; // Assuming ROS-TCP-Connector\r\n\r\npublic class CommandInput : MonoBehaviour\r\n{\r\n    public InputField commandInputField;\r\n    public Button sendCommandButton;\r\n    // public string rosTopicName = "/humanoid_commands"; // ROS 2 topic to publish to\r\n\r\n    void Start()\r\n    {\r\n        if (sendCommandButton != null)\r\n        {\r\n            sendCommandButton.onClick.AddListener(OnSendCommand);\r\n        }\r\n        // ROSConnection.instance.RegisterPublisher<StringMsg>(rosTopicName); // Example ROS publisher setup\r\n    }\r\n\r\n    void OnSendCommand()\r\n    {\r\n        string commandText = commandInputField.text;\r\n        if (!string.IsNullOrWhiteSpace(commandText))\r\n        {\r\n            Debug.Log("Sending command: " + commandText);\r\n            // Example of publishing a ROS 2 message\r\n            // StringMsg commandMsg = new StringMsg(commandText);\r\n            // ROSConnection.instance.Publish(rosTopicName, commandMsg);\r\n            commandInputField.text = ""; // Clear input field\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,o.jsx)(e.p,{children:"This setup allows for rich, interactive visualizations and control interfaces, enhancing the HRI experience with your digital twin."}),"\n",(0,o.jsx)(e.h3,{id:"reference",children:"Reference"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.code,{children:"examples/environments/unity_hri_layout.json"})}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>a});var t=i(6540);const o={},r=t.createContext(o);function s(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);
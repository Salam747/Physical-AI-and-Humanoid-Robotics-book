"use strict";(globalThis.webpackChunkrobotic_book=globalThis.webpackChunkrobotic_book||[]).push([[522],{4724:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>t,contentTitle:()=>l,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module3-ai-brain/isaac-ros-gems-slam","title":"Isaac ROS GEMs for Visual SLAM","description":"This chapter introduces NVIDIA Isaac ROS GEMs, focusing specifically on those designed for Visual SLAM (Simultaneous Localization and Mapping). These GPU-accelerated ROS 2 packages provide high-performance solutions for robots to build 3D maps of their environment while simultaneously tracking their own position within that map.","source":"@site/docs/module3-ai-brain/03-isaac-ros-gems-slam.mdx","sourceDirName":"module3-ai-brain","slug":"/module3-ai-brain/isaac-ros-gems-slam","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/isaac-ros-gems-slam","draft":false,"unlisted":false,"editUrl":"https://github.com/yourusername/physical-ai-humanoid-book/tree/main/docs/module3-ai-brain/03-isaac-ros-gems-slam.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Domain Randomization and Synthetic Data","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/domain-randomization"},"next":{"title":"Isaac ROS GEMs for AprilTag and PeopleNet","permalink":"/Physical-AI-and-Humanoid-Robotics-book/docs/module3-ai-brain/isaac-ros-gems-perception"}}');var s=n(4848),o=n(8453);const r={},l="Isaac ROS GEMs for Visual SLAM",t={},c=[{value:"What are Isaac ROS GEMs?",id:"what-are-isaac-ros-gems",level:2},{value:"Visual SLAM (Simultaneous Localization and Mapping)",id:"visual-slam-simultaneous-localization-and-mapping",level:2},{value:"Isaac ROS VSLAM GEM",id:"isaac-ros-vslam-gem",level:2},{value:"Implementing VSLAM with Isaac ROS",id:"implementing-vslam-with-isaac-ros",level:2},{value:"Example: Building a 3D Map in Simulation (Conceptual Isaac ROS VSLAM)",id:"example-building-a-3d-map-in-simulation-conceptual-isaac-ros-vslam",level:2},{value:"1. Conceptual ROS 2 Launch File (<code>vslam_example.launch.py</code>)",id:"1-conceptual-ros-2-launch-file-vslam_examplelaunchpy",level:3},{value:"Explanation",id:"explanation",level:3},{value:"How to Use (Conceptual)",id:"how-to-use-conceptual",level:3}];function d(e){const a={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.header,{children:(0,s.jsx)(a.h1,{id:"isaac-ros-gems-for-visual-slam",children:"Isaac ROS GEMs for Visual SLAM"})}),"\n",(0,s.jsx)(a.p,{children:"This chapter introduces NVIDIA Isaac ROS GEMs, focusing specifically on those designed for Visual SLAM (Simultaneous Localization and Mapping). These GPU-accelerated ROS 2 packages provide high-performance solutions for robots to build 3D maps of their environment while simultaneously tracking their own position within that map."}),"\n",(0,s.jsx)(a.h2,{id:"what-are-isaac-ros-gems",children:"What are Isaac ROS GEMs?"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Overview"}),": GPU-accelerated ROS 2 packages that provide optimized components for robotics applications."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Benefits"}),": Leverage NVIDIA GPUs for significant performance improvements in computationally intensive tasks like perception and AI."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Integration"}),": Designed for seamless integration into existing ROS 2 systems."]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"visual-slam-simultaneous-localization-and-mapping",children:"Visual SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Purpose"}),": Enabling robots to autonomously navigate unknown environments by constructing a map and localizing themselves within it."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Challenges"}),": Real-time processing, accuracy in dynamic environments, robustness to sensor noise."]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"isaac-ros-vslam-gem",children:"Isaac ROS VSLAM GEM"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Features"}),": High-performance visual odometry and mapping, suitable for edge devices."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Sensor Input"}),": Typically relies on monocular, stereo, or RGB-D cameras."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Outputs"}),": Robot pose (localization), 3D point cloud map (mapping)."]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"implementing-vslam-with-isaac-ros",children:"Implementing VSLAM with Isaac ROS"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Installation"}),": Setting up the Isaac ROS environment and VSLAM GEM."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Configuration"}),": Tuning parameters for different camera types and environments."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Integration with ROS 2"}),": Launching VSLAM nodes and visualizing outputs in RViz2."]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"example-building-a-3d-map-in-simulation-conceptual-isaac-ros-vslam",children:"Example: Building a 3D Map in Simulation (Conceptual Isaac ROS VSLAM)"}),"\n",(0,s.jsx)(a.p,{children:"This conceptual example outlines how you might use an Isaac ROS VSLAM GEM within a simulated environment to build a 3D map. We'll focus on the launch file configuration to integrate the VSLAM node with sensor data from a simulated camera."}),"\n",(0,s.jsxs)(a.h3,{id:"1-conceptual-ros-2-launch-file-vslam_examplelaunchpy",children:["1. Conceptual ROS 2 Launch File (",(0,s.jsx)(a.code,{children:"vslam_example.launch.py"}),")"]}),"\n",(0,s.jsx)(a.p,{children:"This Python launch file would typically:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Launch your simulation environment (e.g., Isaac Sim with a camera)."}),"\n",(0,s.jsxs)(a.li,{children:["Launch a ",(0,s.jsx)(a.code,{children:"ros_bridge"})," to get sensor data (images) from the simulator into ROS 2."]}),"\n",(0,s.jsx)(a.li,{children:"Launch the Isaac ROS VSLAM node, configuring it with the camera topic."}),"\n"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:"# Conceptual ROS 2 Launch File: vslam_example.launch.py\r\nimport os\r\nfrom ament_index_python.packages import get_package_share_directory\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import IncludeLaunchDescription\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch_ros.actions import Node\r\n\r\ndef generate_launch_description():\r\n    # Path to the Isaac ROS VSLAM package\r\n    # vslam_ros_dir = get_package_share_directory('isaac_ros_vslam')\r\n\r\n    # Example: Launching Isaac Sim (conceptual)\r\n    # This would typically be a complex launch file from your simulator setup\r\n    # simulator_launch = IncludeLaunchDescription(\r\n    #     PythonLaunchDescriptionSource([\r\n    #         os.path.join(get_package_share_directory('isaac_sim_example'), 'launch', 'my_robot_sim.launch.py')\r\n    #     ]),\r\n    # )\r\n\r\n    # Isaac ROS VSLAM Node\r\n    # This node takes camera input and produces pose and map data\r\n    vslam_node = Node(\r\n        package='isaac_ros_vslam', # Actual package name for Isaac ROS VSLAM\r\n        executable='isaac_ros_vslam', # Actual executable name\r\n        name='vslam_node',\r\n        output='screen',\r\n        parameters=[\r\n            {\r\n                'enable_localization': True,\r\n                'enable_slam': True,\r\n                'input_odom_frame': 'odom',\r\n                'base_frame': 'base_link',\r\n                'enable_imu_fusion': False, # Assuming no IMU for simplicity\r\n                'gyro_bias_sigma': 0.0001,\r\n                'accel_bias_sigma': 0.001,\r\n                'calibration_preset': 'realsense', # Example preset\r\n                # Input topics from the simulated camera\r\n                'image_topic': '/camera/image_raw',\r\n                'camera_info_topic': '/camera/camera_info',\r\n                'depth_topic': '/camera/depth/image_raw',\r\n            }\r\n        ],\r\n        remappings=[\r\n            ('/stereo_camera/left/image_rect', '/camera/image_raw'), # Example remapping\r\n            ('/stereo_camera/left/camera_info', '/camera/camera_info'),\r\n        ]\r\n    )\r\n\r\n    # Conceptual RViz2 node for visualization\r\n    # rviz_node = Node(\r\n    #     package='rviz2',\r\n    #     executable='rviz2',\r\n    #     name='rviz_vslam',\r\n    #     output='screen',\r\n    #     arguments=['-d', os.path.join(vslam_ros_dir, 'rviz', 'vslam.rviz')] # Conceptual Rviz config\r\n    # )\r\n\r\n    return LaunchDescription([\r\n        # simulator_launch, # Uncomment if you have a simulator launch\r\n        vslam_node,\r\n        # rviz_node # Uncomment for visualization\r\n    ])\n"})}),"\n",(0,s.jsx)(a.h3,{id:"explanation",children:"Explanation"}),"\n",(0,s.jsx)(a.p,{children:"This conceptual launch file demonstrates how to integrate the VSLAM GEM:"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Node Definition"}),": The ",(0,s.jsx)(a.code,{children:"Node"})," action defines the ",(0,s.jsx)(a.code,{children:"isaac_ros_vslam"})," node."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Parameters"}),": Key parameters are passed, such as ",(0,s.jsx)(a.code,{children:"enable_localization"}),", ",(0,s.jsx)(a.code,{children:"enable_slam"}),", and importantly, the input topics for ",(0,s.jsx)(a.code,{children:"image_topic"}),", ",(0,s.jsx)(a.code,{children:"camera_info_topic"}),", and ",(0,s.jsx)(a.code,{children:"depth_topic"})," which would come from your simulated camera."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Remapping"}),": ",(0,s.jsx)(a.code,{children:"remappings"})," can be used to align topic names from your simulator to what VSLAM expects."]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"how-to-use-conceptual",children:"How to Use (Conceptual)"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:["Set up your simulated environment (e.g., in Isaac Sim) with a camera publishing ROS 2 topics (",(0,s.jsx)(a.code,{children:"/camera/image_raw"}),", ",(0,s.jsx)(a.code,{children:"/camera/camera_info"}),", ",(0,s.jsx)(a.code,{children:"/camera/depth/image_raw"}),")."]}),"\n",(0,s.jsxs)(a.li,{children:["Ensure you have the ",(0,s.jsx)(a.code,{children:"isaac_ros_vslam"})," package installed in your ROS 2 workspace."]}),"\n",(0,s.jsx)(a.li,{children:"Build your workspace and source it."}),"\n",(0,s.jsxs)(a.li,{children:["Launch the VSLAM example:","\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-bash",children:"ros2 launch your_package_name vslam_example.launch.py\n"})}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["Open RViz2 (if not launched automatically) and add displays for ",(0,s.jsx)(a.code,{children:"PointCloud2"})," (for map), ",(0,s.jsx)(a.code,{children:"TF"})," (for robot pose), and ",(0,s.jsx)(a.code,{children:"Camera"})," (for image output) to visualize the VSLAM process."]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"This setup allows the robot to process simulated sensor data and build a 3D map of the virtual environment."})]})}function m(e={}){const{wrapper:a}={...(0,o.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>r,x:()=>l});var i=n(6540);const s={},o=i.createContext(s);function r(e){const a=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:a},e.children)}}}]);